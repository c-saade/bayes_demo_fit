---
title: "Unraveling Time Series with RStan: A Bayesian Approach to Demographic Modeling"
author: "Camille Saade"
date: '2023-07-27'
output:
  html_document:
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Demographic models are an invaluable tool in ecology, as they offer insights into the dynamics of species over time.
By estimating ecologically relevant parameters - such as growth rates and competition strength - these models shed light on complex ecological systems and eventually to predict their future dynamics or produce in-silico experiments.

However, fitting these models can be quite complex and using them for prediction requires robust parameter estimation for prediction purpose.
In particular, traditional frequentist approaches often lack the flexibility to accomodate complex models and they offer point estimates which risk missing identifiability issues.
Bayesian approaches on the other hand, are well suited to estimate parameter distributions and allow to identify pathological correlations between parameters at a glance.

In this article, we will use RStan - a bayesian statistical R package - to analyze time series of two interacting species and find out the mechanisms underlying their dynamics.

## Data

In one of my [research projects](https://doi.org/10.1098/rspb.2022.0543) I studied ecosystems recovery dynamics using microcosms - _i.e._, small laboratory ecosystems made up of microorganisms.
To overcome laboratory limitations of experiment duration and ecosystem size, I also reproduced and expanded the experiment _in silico_.
To get a robust parameterization of the simulations, I fitted a demographic model to preliminary data.
We will work with this preliminary data, consisting of growth curves of several unicellular species in isolation and in co-culture.
All species feed on the same resource and are thus in competition when grown together.
Let's first load and inspect the data:

```{r}
density_data = read.csv("./Data/density_data.csv", header = T, sep = ',')
head(density_data, 10)
```

Each line contains the density (individuals/mL) of each species in one of the tubes (identified by the column 'file') at a given point in time (given either by the columns 'date' and 'time' or by the column 'hours').
Each species association ('community') was replicated three times, and replicates are differentiated using the 'replicate' column.
The columns 'Tet', 'Pca', 'Ble' and 'Col' describe the density of four unicellular species, respectively _Tetrahymena thermophila_, _Paramecium caudatum_, _Colpidium_ sp. and _Blepharisma_ sp.

Here is a summary of the columns content:

  - "file": the name of the video sample used for species count and identification, serves as a unique id for each tube.
  - "date": date at which the sample was taken (yyyy-mm-dd).
  - "time": the time of day at which the sample was taken (hour).
  - "community": the species grown in a tube.
  - "replicate": the replicate number.
  - "measure_point": the number of the measurement (t0 to t11)
  - "Tet": the density (individuals/mL) of _Tetrahymena thermophila_
  - "Pca": the density (individuals/mL) of _Paramecium caudatum_ (a species initially considered in the pilot, not used in the final study)
  - "Col": the density (individuals/mL) of _Colpidium_ sp.
  - "Ble": the density (individuals/mL) of _Blepharisma_ sp.
  - "hours": the time passed since the beginning of the culture (in hours).

Let us take a look at the data:
```{r, warning=FALSE, message = FALSE}
# plotting the whole data
library(tidyverse)
theme_set(theme_light())
density_data %>%
  mutate(Ble = replace(Ble, !grepl('Ble', community), NA)) %>%
  mutate(Col = replace(Col, !grepl('Col', community), NA)) %>%
  mutate(Tet = replace(Tet, !grepl('Tet', community), NA)) %>%
  mutate(Pca = replace(Pca, !grepl('Pca', community), NA)) %>%
  pivot_longer(cols = c("Ble", "Col", "Tet", "Pca"),
               names_to = "species",
               values_to = "density") %>%
  ggplot() +
  geom_point(mapping = aes(x = hours, y = density, color = species)) +
  geom_line(mapping = aes(x = hours, y = density, color = species, group = interaction(species, replicate)), alpha = 0.5) +
  scale_y_continuous(trans='log2') +
  facet_wrap(community ~ .) +
  ylab('Species density (log2(indiv./mL))') +
  xlab('Time (h)')
```
We show here the density (on a log scale) over time of species for each species combination.
This makes a large data set on which to fit a single model.
For the sake of simplicity, we will work only on a subset of the data: the co-culture of _Blepharisma_ sp. and _Tetrahymena_ sp., and we will average the data across replicates.
If you wish to explore how to take advantage of monocultures, tri-cultures and replications, you can have a look into the papers [data and code](https://doi.org/10.5281/zenodo.6364903).
Let's filter the data and average across replicates:

```{r}
# filtering data
filtered_data <- 
  density_data %>%
  filter(community == 'Ble_Tet') %>% # keeping only the bi-specific time series (Blepharisma sp. + Tetrahymena sp.)
  select(c(measure_point, hours, Ble, Tet)) %>% # keeping only time variables and species densities
  group_by(measure_point) %>% # averaging each measurement over replicates
  summarise(t = mean(hours), n1 = mean(Ble), n2 = mean(Tet)) %>%
  arrange(t) # sorting by time
```

```{r}
# plotting the resulting data
library(ggpubr)

panel_a = ggplot(data = filtered_data) +
  geom_point(mapping = aes(x = t, y = n1), color = 'blue') +
  xlab('Time (h)') +
  ylab('Density of Blepharisma sp. (indiv./mL)')

panel_b = ggplot(data = filtered_data) +
  geom_point(mapping = aes(x = t, y = n2), color = 'red') +
  xlab('Time (h)') +
  ylab('Density of Tetrahymena sp. (indiv./mL)')

ggarrange(panel_a, panel_b, nrow = 2)
```

We end up with a single time series for _Blepharisma_ sp. (blue) and for _Tetrahymena_ sp. (red), which is much more manageable in the context of this guide.
For now we can only describe the dynamics verbally: the population _Tetrahymena thermophila_ grows very fast, reaching a fairly high density of 6000 individuals per mL under 100 hours, before crashing down as the population of _Blepharisma_ sp. grow.
On the opposite, the population of _Blepharisma_ sp. grows fairly slowly, seemingly reaching an equilibrium density of 150 individuals per mL in over 200 hours.
Fitting a demographic model onto this data would allow us to numerically quantify these observations as well as unobservable quantities such as competition rates.

Before delving into the model specifics, the last thing we want to do is transform this data into a list that is manageable by Rstan:

```{r}
# turning data into a list to give to the Rstan sampler.
data = list(n  = nrow(filtered_data), # number of observations
            t = filtered_data$t, # vector of times
            n1 = filtered_data$n1, # vector of density of species 1 (Ble)
            n2 = filtered_data$n2) # vector of density of species 2 (Tet)
```

## Demographic model

Species dynamics in ecology are often described using differential equations describe the instantaneous growth rate as a function of the species density.
The go-to model to describe the dynamics of two species in competition is the [competitive Lotka-Volterra model](https://en.wikipedia.org/wiki/Competitive_Lotka%E2%80%93Volterra_equations):

$$
\begin{aligned}
\dfrac{dn_1}{dt} = r_1 n_1 \left(1 - \dfrac{n_1 + \alpha_1 n_2}{K_1} \right)\\
\dfrac{dn_2}{dt} = r_2 n_2 \left(1 - \dfrac{n_2 + \alpha_2 n_1}{K_2} \right)
\end{aligned}
$$
With the following variables:

  - $t$, the time.
  - $n_1$ and $n_2$, the densities of species 1 and 2.
  
And the following parameters

  - $r_1$ and $r_2$, the growth rates of species 1 and 2.
  - $K_1$ and $K_2$, the carrying capacities of species 1 and 2 (_i.e._, their equilibrium density when grown in isolation).
  - $\alpha_1$ and $\alpha_2$, the competition rates: $\alpha_1$ measures the effect that an individual of species 2 has on the growth of species 1 and conversely.
$\alpha_1 \sim 0$ would mean that species 2 has no effect on species 1 (_e.g._, if species 1 is way more efficient than species 2, or if the two species do not compete for the same resource).
$\alpha_1 \sim 1$ would mean that the two species are competitively equivalent.
$\alpha_1 > 1$ would mean that species 2 has a strong negative effect on the growth of species 1.

We thus need to infer the 6 model parameters ($r_1$, $r_2$, $K_1$, $K_2$, $\alpha_1$, $\alpha_2$) as well as the initial conditions for species densities since the measured initial conditions suffer from measurement errors and cannot be used as true values. We will write these initial conditions $n_{10sim}$ and $n_{20sim}$.

## Stan implementation

We can specify the model in [stan's programming language](https://mc-stan.org/docs/reference-manual/index.html), a pseudo C language.
We write the model as a string (or a text file) organized in several blocks:

  - ```functions```: to declare any utility functions necessary to the fit.
  - ```data```: to declare the structure (type, size...) of the data fed to the model.
  - ```parameters```: to declare the model parameters.
  - ```model```: to declare parameter priors and how to compute the likelyhood.
  - ```generated quantities```: to declare any quantity we want the sampler to compute along the way.
  
Let's declare and compile the model in the next code chunk before explaining each bloc in detail:
  
```{r, eval = FALSE}
# loading rstan
library(rstan)

# declaring the model as a string
model_str = '
functions{
  real[] odemodel(real t, real[] N, real[] p, real[] x_r, int[] x_i){
    // p[1]=r1, p[2] = r2, p[3] = K1, p[4] = K2, p[5] = alpha1, p[6] = alpha2 
    real dNdt[2]; 
    dNdt[1] = p[1]*N[1]*(1 - (N[1] + p[5]*N[2])/p[3]);
    dNdt[2] = p[2]*N[2]*(1 - (p[6]*N[1] + N[2])/p[4]);
    return dNdt;
  }
}

data{
  int n; // number of observations
  real t[n]; // time
  real n1[n]; // observations n1
  real n2[n]; // observations n2
}

parameters{
  real<lower=0> r1; // growth rate
  real<lower=0> r2; // growth rate
  real<lower=0> K1; // carrying capacity
  real<lower=0> K2; // carrying capacity
  real<lower=0> alpha1; // comp term
  real<lower=0> alpha2; // comp term
  real<lower=0> n10sim; // initial density n1
  real<lower=0> n20sim; // initial density n2
  real<lower=0> sdev1;
  real<lower=0> sdev2;
}

model{
  real p[6]; // vector of parameters for the ODE
  real simval[n-1,2]; // simulated values, matrix. dim1 = time without t0, dim2 = dim_ODE = 2 (S = 1, I = 2)
  
  // priors 
  r1 ~ lognormal(-3,1);
  r2 ~ lognormal(-2,1);
  K1 ~ lognormal(5, 0.8);
  K2 ~ lognormal(8, 0.5);
  alpha1 ~ lognormal(-3,1);
  alpha2 ~ lognormal(2.5,1);
  n10sim ~ normal(n1[1],5);
  n20sim ~ normal(n2[1],10);
  sdev1 ~ gamma(1, 1);
  sdev2 ~ gamma(1, 1);
  
  // parameters for integrator
  p[1] = r1;
  p[2] = r2;
  p[3] = K1;
  p[4] = K2;
  p[5] = alpha1;
  p[6] = alpha2;

  // integrate ODE
  simval = integrate_ode_rk45(odemodel, {n10sim, n20sim}, t[1], t[2:n], p, rep_array(0.0,0), rep_array(0,0));
  // likelihood
  n1[1] ~ normal(n10sim, sdev1);
  n2[1] ~ normal(n20sim, sdev2);
  for (i in 2:n){
    n1[i] ~ normal(simval[i-1, 1], sdev1);
    n2[i] ~ normal(simval[i-1, 2], sdev2);
  }
}

generated quantities{
  real r_ratio = r1/r2;
  real alpha_ratio = alpha1/alpha2;
}
'

# compiling the model
model = stan_model(model_code=model_str)
```

### functions

The only function we need here is a the ODE of the Lotka-Volterra model.
At each step, the sample will use it to simulate the dynamics of a given set of parameters which will serve to compute the likelihood.

```{}
functions{
  real[] odemodel(real t, real[] N, real[] p, real[] x_r, int[] x_i){
    // p[1]=r1, p[2] = r2, p[3] = K1, p[4] = K2, p[5] = alpha1, p[6] = alpha2 
    real dNdt[2]; 
    dNdt[1] = p[1]*N[1]*(1 - (N[1] + p[5]*N[2])/p[3]);
    dNdt[2] = p[2]*N[2]*(1 - (p[6]*N[1] + N[2])/p[4]);
    return dNdt;
  }
}
```



### data

Here we declare the data that we will give to the sampler:

  - ```n``` is an integer describing the number of observations, which we need to declare the length of the data vectors.
  - ```t``` it the vector of times, in hours.
  - ```n1``` and ```n2``` are the vectors of species densities.
  
```{}
data{
  int n; // number of observations
  real t[n]; // time
  real n1[n]; // observations n1
  real n2[n]; // observations n2
}
```



### parameters

Here we declare the model parameters, _i.e._, the quantities that the sampler need to estimate:
  
  - the ```r```'s, ```K```'s and ```alpha```'s are the parameters for the Lotka-Volterra model
  - ```n10sim``` and ```n_20sim``` are the initial densities of both species. As stated above, they need to be estimated as parameters to avoid propagating the error from erroneous measures of the initial conditions.
  - ```sdev1``` and ```sdev2``` are parameters for the residual distribution of species 1 and 2.
  

```{}
parameters{
  real<lower=0> r1; // growth rate
  real<lower=0> r2; // growth rate
  real<lower=0> K1; // carrying capacity
  real<lower=0> K2; // carrying capacity
  real<lower=0> alpha1; // comp term
  real<lower=0> alpha2; // comp term
  real<lower=0> n10sim; // initial density n1
  real<lower=0> n20sim; // initial density n2
  real<lower=0> sdev1;
  real<lower=0> sdev2;
}
```


### model

Finally, we can write the bulk of the model.
This block is used to declare how to compute the likelyhood from a given set of parameters.
To do so, we need to declare the parameters prior distributions, to write down how to simulate dynamics and finally how to compute likelyhood from simulated dynamics and data.

We first declare the variables that will be used in this block.
We need to declare a vector ```p``` to feed the parameters of the Lotka-Volterra model to rstan's integrator.
```simval``` is the vector in which we will store the outpout of the numerical integration. It is of length ```n-1``` because the initial conditions are estimated as a parameter, and of width 2 to store the densities of both species.
```{}
model{
  real p[6]; // vector of parameters for the ODE
  real simval[n-1,2]; // simulated values, matrix. dim1 = time without t0, dim2 = dim_ODE = 2 (S = 1, I = 2)
```


Next, we need to declare a prior distribution of all parameters.
Prior distributions will constrain the parameter space explored by the sampler.
Uninformative priors can lead to very slow sampling and convergence issues, while very informative priors keep the model from exploring less common but plausible parameters.
We thus want to set priors that make sense with our data _i.e._, that lie within a reasonable range.
We can do so by visually estimating order of magnitude for most parameters:

  - Growth rates (```r1``` and ```r2```) order of magnitude can be roughly estimated from the population doubling time at low density ($r \sim \dfrac{1}{doubling\ time}$).
  - Carrying capacities (```K1``` and ```K2```) order of magnitude can be roughly estimated using the maximum density.
  - Competition rates (```aplpha1``` and ```alpha2```) order of magnitude are a bit tougher to estimate. However, we can safely estimate that $$\alpha_1 << 1$$ since _Blepharisma_ sp. is able to grow despite the large density of _Tetrahymena_ sp. and that $$\alpha_2 >> 1$$ since the population of _Tetrahymena_ sp. declines when _Blepharisma_ sp. starts to grow.
  - The initial densities (```n10sim``` and ```n20sim```) can be estimated to be on the same order of magnitude as the measured initial densities.
  
  Once we have rough estimates, we chose priors centered on these estimates and with a variance reflecting the confidence we have on our estimate:

```{}
  // priors 
  r1 ~ lognormal(-3,1);
  r2 ~ lognormal(-2,1);
  K1 ~ lognormal(5, 0.8);
  K2 ~ lognormal(8, 0.5);
  alpha1 ~ lognormal(-3,1);
  alpha2 ~ lognormal(2.5,1);
  n10sim ~ normal(n1[1],5);
  n20sim ~ normal(n2[1],10);
  sdev1 ~ gamma(1, 1);
  sdev2 ~ gamma(1, 1);
```

We fill in the vector ```p```.
```{}
  // parameters for integrator
  p[1] = r1;
  p[2] = r2;
  p[3] = K1;
  p[4] = K2;
  p[5] = alpha1;
  p[6] = alpha2;
```

We then simulate dynamics using the function ```odemodel``` that we declared in the ```functions``` block and store them in ```simval```
```{}
  // integrate ODE
  simval = integrate_ode_rk45(odemodel, {n10sim, n20sim}, t[1], t[2:n], p, rep_array(0.0,0), rep_array(0,0));
```

Finally, we compute the likelihood by comparing simulated values and data.
We chose to consider that the observed data points are normally distributed around the simulated values.
This way, large discrepancies between the data and simulated values will result in a low likelihood.

```{}
  // likelihood
  n1[1] ~ normal(n10sim, sdev1);
  n2[1] ~ normal(n20sim, sdev2);
  for (i in 2:n){
    n1[i] ~ normal(simval[i-1, 1], sdev1);
    n2[i] ~ normal(simval[i-1, 2], sdev2);
  }
}
```

### generated quantities

Finally, we can ask the sampler for generated quantities.
For exemple, we might be interested in ratio of parameters between species to see at a glance how fast a species grows or how well is competes against the other species.
We do so by declaring two new variables, ```r_ratio``` and ```alpha_ratio```:

```{}
generated quantities{
  real r_ratio = r1/r2;
  real alpha_ratio = alpha1/alpha2;
}
```

### Model fit

Once the model is declared and compiled, we can get into the fit itself.
We first declare some hyperparameters (parameters of the sampler) and then run the fit:

```{r, eval = FALSE}
# stan options
  # number of parallel chains
  chains = 4
  options(mc.cores = chains)
  
  # number of total iterations and warm-up steps
  iter   =  10000
  warmup =  2000
  
  # initial parameters choice
  init=rep(list(list(r1=0.01,
                   r2=0.1,
                   K1 = 150,
                   K2 = 4000,
                   alpha1 = 1,
                   alpha2 = 1,
                   n10sim=5,
                   n20sim=500,
                   sdev1 = 1,
                   sdev2 = 1)), chains)
# model fit
fit_obs = sampling(model,
                  data=data,
                  iter=iter,
                  warmup=warmup,
                  chains=chains,
                  init=init,
                  control = list(adapt_delta = 0.9, max_treedepth=12))

save(fit_obs, file="./out/fit_posterior.RData")
```

```{r, include = FALSE, echo = FALSE}
library(rstan)
load("./out/fit_posterior.RData")
```

## Model diagnostic

Once the model is fitted, we need to diagnose the output to ensure that there is no pathological behavior.
In particular, we want to ensure that the different chains are well mixed (_i.e._, that the four independent fit end up in the same place) and that parameters are well identifiable.

### Checking R-hat and n_eff
The first thing we can do is check some summary statistics.

```{r}
print(fit_obs)
```

Printing the model fit yields summary statistics for all infered parameters.
Pay close attention to the last two statistics, ```n_eff``` and ```Rhat```.

```n_eff``` is a measure of the effective number of samples.
Here, all parameters have more than 6000 effective samples, which should give us a good description of the posterior shape.

```Rhat``` is a measure of chain mixing: it is roughly a measure of inter-chain variability over intra-chain variability.
The closer ```Rhat``` is to 1, the better mixed the chains are, indicating that the model converged.
We usually consider that fit with some Rhat larger that 1.01 have not reached convergence and should be run longer.
Here, all Rhat are displayed as 1 (rounded with at decimal places) so the model has converged.

### Inspecting chains
We can also inspect the posteriors visually by looking at the trace and density plots.
Trace plots show the parameters values over iterations, density plots show the posterior distribution of parameters.
For a healthy sample, trace plots should look stationnary (constant mean over iteration) with indistinguishable chains, and density plots should be unimodal.
Everything here looks good.

```{r, eval = FALSE}
library(coda)
params = c("r1","r2", "K1", "K2", "alpha1", "alpha2", "r_ratio", "alpha_ratio")
samples=As.mcmc.list(fit_obs)
traceplot(samples[, params[1:6]])
```
```{r, echo = FALSE, message=FALSE}
library(coda)
params = c("r1","r2", "K1", "K2", "alpha1", "alpha2", "r_ratio", "alpha_ratio")
samples=As.mcmc.list(fit_obs)
plot(samples[, params[1:2]])
plot(samples[, params[3:4]])
plot(samples[, params[5:6]])
```

### Pair plots
Lastly, we can check the pair plot of the posteriors.
We want to ensure that there is no near perfect correlation between parameters, which would indicate non identifiability.
```{r, warning=FALSE}
pairs(fit_obs, pars=params)
```



## Posterior predictions

```{r}
library(deSolve)
```


```{r}
# declaring the lotka-volterra model
ode.model = function(t,N,p){
  r1 = p$r1
  r2 = p$r2
  K1 = p$K1
  K2 = p$K2
  alpha1 = p$alpha1
  alpha2 = p$alpha2
  dn1 = r1*N[1]*(1-(N[1]+alpha1*N[2])/K1)
  dn2 = r2*N[2]*(1-(alpha2*N[1]+N[2])/K2)
  return(list(c(dn1, dn2)))
}
```

```{r}
# sampling 1000 values from the posterior distribution and
# computing the predicted dynamics for each
n_post = 1000
times = seq(min(data$t), max(data$t), length.out = 200)
posteriors = as.matrix(fit_obs)
for (k in 1:n_post){
  par = posteriors[sample(1:nrow(posteriors), 1),]
  sim = ode(c(par['n10sim'], par['n20sim']),
            times, ode.model, list(r1 = par['r1'],
                                   r2= par['r2'],
                                   K1 = par['K1'],
                                   K2 = par['K2'],
                                   alpha1 = par['alpha1'],
                                   alpha2 = par['alpha2']),
            method = 'ode45')
  
  temp  = data.frame(time = sim[,1], n1 = sim[,2], n2 = sim[,3], id = k)
  
  if (k == 1) {
    predictions = temp
  } else {
    predictions = rbind(predictions, temp)
  }
}
```

```{r}
# plotting the 1000 predictions over the data
panel_a = ggplot(filtered_data) +
  geom_point(mapping = aes(x = t, y = n1), color = 'blue') +
  geom_line(data = predictions, mapping = aes(x = time, y = n1, group = id), color = 'blue', alpha = 0.01) +
  xlab('') +
  ylab('Density of Blepharisma sp. (indiv./mL)')

panel_b = ggplot(filtered_data) +
  geom_point(mapping = aes(x = t, y = n2), color = 'red') +
  geom_line(data = predictions, mapping = aes(x = time, y = n2, group = id), color = 'red', alpha = 0.01) +
  xlab('Time (h)') +
  ylab('Density of Tetrahymena sp. (indiv./mL)')

ggarrange(panel_a, panel_b, nrow = 2)
```

